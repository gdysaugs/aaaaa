#!/usr/bin/env python3
"""
GPU Test Script for GPT-SoVITS v4 CLI Environment
RTX3050 CUDA 12.4 compatibility check
"""

import sys
import subprocess

def run_nvidia_smi():
    """nvidia-smiã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦GPUæƒ…å ±ã‚’è¡¨ç¤º"""
    print("=== NVIDIA-SMI Information ===")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print(result.stdout)
            return True
        else:
            print(f"nvidia-smi failed: {result.stderr}")
            return False
    except FileNotFoundError:
        print("nvidia-smi command not found!")
        return False
    except Exception as e:
        print(f"Error running nvidia-smi: {e}")
        return False

def test_pytorch_cuda():
    """PyTorchã®CUDAæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n=== PyTorch CUDA Test ===")
    try:
        import torch
        print(f"PyTorch Version: {torch.__version__}")
        
        # CUDAåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        cuda_available = torch.cuda.is_available()
        print(f"CUDA Available: {cuda_available}")
        
        if cuda_available:
            # CUDAè©³ç´°æƒ…å ±
            print(f"CUDA Version: {torch.version.cuda}")
            print(f"cuDNN Version: {torch.backends.cudnn.version()}")
            
            # GPUæƒ…å ±
            device_count = torch.cuda.device_count()
            print(f"Device Count: {device_count}")
            
            for i in range(device_count):
                device_name = torch.cuda.get_device_name(i)
                memory_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"GPU {i}: {device_name} ({memory_total:.1f}GB)")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³
            if device_count > 0:
                torch.cuda.set_device(0)
                memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
                memory_cached = torch.cuda.memory_reserved(0) / 1024**3
                print(f"Memory Allocated: {memory_allocated:.2f}GB")
                print(f"Memory Cached: {memory_cached:.2f}GB")
            
            # ç°¡å˜ãªCUDAæ¼”ç®—ãƒ†ã‚¹ãƒˆ
            print("\n=== CUDA Computation Test ===")
            device = torch.device('cuda:0')
            test_tensor = torch.randn(1000, 1000, device=device)
            result = torch.matmul(test_tensor, test_tensor.t())
            print(f"CUDA computation test passed! Result shape: {result.shape}")
            
            return True
        else:
            print("CUDA is not available in PyTorch!")
            return False
            
    except ImportError:
        print("PyTorch is not installed!")
        return False
    except Exception as e:
        print(f"Error testing PyTorch CUDA: {e}")
        return False

def test_environment_variables():
    """ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª"""
    print("\n=== Environment Variables ===")
    import os
    
    cuda_vars = [
        'CUDA_VISIBLE_DEVICES',
        'NVIDIA_VISIBLE_DEVICES', 
        'PYTORCH_CUDA_ALLOC_CONF',
        'TOKENIZERS_PARALLELISM'
    ]
    
    for var in cuda_vars:
        value = os.environ.get(var, 'Not set')
        print(f"{var}: {value}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("GPT-SoVITS v4 GPU Test Script")
    print("=" * 50)
    
    # nvidia-smi ãƒ†ã‚¹ãƒˆ
    smi_ok = run_nvidia_smi()
    
    # PyTorch CUDA ãƒ†ã‚¹ãƒˆ
    torch_ok = test_pytorch_cuda()
    
    # ç’°å¢ƒå¤‰æ•°ç¢ºèª
    test_environment_variables()
    
    # çµæœåˆ¤å®š
    print("\n" + "=" * 50)
    print("=== Test Results ===")
    print(f"NVIDIA-SMI: {'âœ“ PASS' if smi_ok else 'âœ— FAIL'}")
    print(f"PyTorch CUDA: {'âœ“ PASS' if torch_ok else 'âœ— FAIL'}")
    
    if smi_ok and torch_ok:
        print("\nğŸ‰ All tests passed! GPU environment is ready for GPT-SoVITS v4!")
        return 0
    else:
        print("\nâŒ Some tests failed. Please check your GPU setup.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 