# GPT-SoVITS v4 CLI Test Environment - PyTorch 2.6 Edition
# RTX3050 + CUDA 12.4対応版
# 2025年2月版: torch.load脆弱性対策済み

services:
  gpt-sovits-v4-cli:
    build:
      context: .
      dockerfile: Dockerfile.v2.6
      args:
        BUILDKIT_INLINE_CACHE: 1
      target: final
    image: gpt-sovits-v4-cli:pytorch2.6-cuda12.6
    container_name: gpt-sovits-v4-cli-pytorch26
    
    # GPU設定
    runtime: nvidia
    
    # 環境変数統合
    environment:
      # GPU関連
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # RTX3050最適化メモリ管理
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,roundup_power2_divisions:2
      - CUDA_VISIBLE_DEVICES=0
      
      # PyTorch 2.6対応設定（修正版）
      - CXX11_ABI=1
      - TORCH_USE_CUDA_DSA=1
      - TORCH_LOGS=dynamic,inductor
      
      # セキュリティ設定（torch.load対策）
      - TORCH_WARN_ONLY=0
      
      # API設定
      - API_HOST=0.0.0.0
      - API_PORT=9880
      
      # ログ設定
      - PYTHONUNBUFFERED=1
      - CUDA_LAUNCH_BLOCKING=0
    
    # リソース制限統合（RTX3050: 4GB VRAM）
    deploy:
      resources:
        limits:
          memory: 12G  # システムRAM制限
        reservations:
          memory: 8G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
      
    # ポートマッピング
    ports:
      - "9880:9880"    # API Server
      - "7860:7860"    # Gradio UI (optional)
      
    # ボリュームマウント
    volumes:
      # モデル永続化
      - ./models:/workspace/models
      - ./pretrained_models:/workspace/pretrained_models
      
      # 入出力ディレクトリ
      - ./input:/workspace/input
      - ./output:/workspace/output
      - ./reference:/workspace/reference
      
      # ログ・設定
      - ./logs:/workspace/logs
      - ./configs:/workspace/configs
      
      # GPT/SoVITS重み
      - ./GPT_weights:/workspace/GPT_weights
      - ./SoVITS_weights:/workspace/SoVITS_weights
      
      # テストサンプル
      - ./test_samples:/workspace/test_samples
      
    # ネットワーク設定
    networks:
      - gpt-sovits-network
      
    # 再起動ポリシー
    restart: unless-stopped
    
    # ヘルスチェック
    healthcheck:
      test: ["CMD", "python3", "-c", "import torch; exit(0 if torch.cuda.is_available() else 1)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
              
    # セキュリティ設定
    security_opt:
      - seccomp:unconfined
      
    # ユーザー設定
    user: "1000:1000"
    
    # 作業ディレクトリ
    working_dir: /workspace
    
    # デフォルトコマンド
    command: ["/workspace/check_gpu.sh"]

  # 開発用サービス（オプション）
  gpt-sovits-dev:
    extends:
      service: gpt-sovits-v4-cli
    container_name: gpt-sovits-v4-dev-pytorch26
    
    # 開発モード設定
    environment:
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/workspace/GPT-SoVITS
      
      # PyTorch 2.6対応設定（修正版）
      - CXX11_ABI=1
      - TORCH_USE_CUDA_DSA=1
      - TORCH_LOGS=dynamic,inductor
      
    # 追加ボリューム（開発用）
    volumes:
      - ./:/workspace/development
      
    # 開発用ポート
    ports:
      - "9881:9880"  # 開発API Server
      - "7861:7860"  # 開発Gradio UI
      
    # 開発コマンド
    command: ["bash", "-c", "tail -f /dev/null"]

# ネットワーク定義
networks:
  gpt-sovits-network:
    driver: bridge
    name: gpt-sovits-v4-network

# ボリューム定義（オプション）
volumes:
  gpt-sovits-models:
    driver: local
    name: gpt-sovits-v4-models
    
  gpt-sovits-cache:
    driver: local
    name: gpt-sovits-v4-cache 